Machine Learning Crash Course:

Linear regression is a kind of statistical analysis that attempts 
to show a relationship between two variables. 
Linear regression looks at various data points and plots a trend line. 
Linear regression can create a predictive model on apparently random data,
showing trends in data.


Regressão Linear: O relacionamento das variáveis é linear, desse modo
trata-se de uma função definida por: y = mx + b

Por convenção em Machine Learning a equação que representa um modelo é 
um pouco diferente: y' = b + w1x1

Onde:
	y' = É a variavel que se deseja prever(label ou rótulo);
	b  = Trata-se do viés, muitas vezes referido como (w0);
	w1 = É o peso ou relevência do fator 1;
	x1 = É a variável de entrada(feature);

Inferir(prever) basta substituir o valor x1 por algum outro valor.

O modelo acima utiliza apenas uma variável de entrada, ou uma feature,
modelos mais sofisticados possuem várias features: y' = b + w1x1 + w2x2 + w3x3

Treino e Perda

Treinar um modelo é simplesmente encontrar os pesos ideias para as variáveis
de entrada. Em aprendizado supervisionado 
os algoritimos de machine learning utilizam vários exemplos(dados) e procuram
diminuir a perda. Perda é a diferença entre o valor previsto e o valor real.
O algoritimo perfeito possuí perda zero. Treinar o modelo é encontrar os 
pesos e viés possuem a menor perda entre todos os exemplos plotados.

Duas medidas de erro são: 
Erro quadrático: (valor_real - valor_previsto)² 
Erro quadrático médio: Trata-se média da soma dos erros quadráticos.

Existem muitas outras funções de perda os exemplos acima são os mais básicos.

Reduzindo a Perda:
	Para treinar um modelo é necessária uma boa maneira de diminuir
o seu erro. A princípio, o algoritimo utiliza um valor 
aleatório como peso para uma ou várias determinadas variáveis, 
realiza uma iteração e avalia o erro encontrado, depois o valor dos pesos 
é recalculado com um novo valor, um pouco acima ou um pouco abaixo que o 
anterior e novamente avalia o erro. E assim sucessivamente até que o melhor 
valor seja encontrado, ou seja aquele que diminui o erro/perda ao máximo.
Quando este valor é encontrado e dito que o modelo CONVERGIU.

Gradiente Descendente:

Supondo que tenhamos tempo e recursos computacionais ilimitados para calcular
a perda para todos os possíveis valores de peso para uma variável.
As curvas de perda para problemas de regressão linear são normalmente convexas.
Problemas convexos possuem apenas um valor minímo, onde o quoeficiente angular
é zero. Este ponto é onde a função de perda converge. Calcular cada possível
valor que w1(peso) é uma maneira ineficiente de encontrar o ponto de convergência.
Um mecanismo muito popular em machine Learning é o Gradiente Descendente.

Dada a função de perda, o algoritimo seleciona um valor aleatório para iniciar 
e calcula o gradiente para o ponto selecionado na curva da função. 
O gradiente é um vetor que possuí duas caracteristicas: Uma direção e uma magnitude. Ele 
aponta para direção de maior variação dentro da curva da função de perda.  No caso do
gradiente descente a direção do seu vetor é negativa (direção que a função de perda é cada
vez menor). A cada passo do gradiente, uma fração do valor de magnitude do vetor é 
selecionada e o processo é repetido até que a direção do vetor inverta. Caso a função
escolhida tenha mais um parametro, o algoritimo do gradiente descente é aplicado 
simultaneamente para ambos parametros.
A direção e magnitude do vetor são multiplicadas por um escalar conhecido como taxa de
aprendizado, esse valor irá determinar o próximo ponto do gradiente na curva de perda. 
Esse escalar é um hiperparametro utilizado para refinar o algoritimos de machine learning.
Se a taxa de aprendizado foi muito baixa, o processo de aprendizado se torna demorado, 
caso contrário, o próximo ponto do gradiente na curva de perda pode ultrapassar em muito
o valor minimo da função de perda. Todo problema de regressão, possuí uma taxa adequada
de aprendizado.

//EXERCICIOS PARA REDUÇÃO DE PERDA E OTIMIZAÇÃO DE TAXA DE APRENDIZADO.//

Gradiente Descendente Estocástico:
No gradiente descente "batch" é o número total de exemplos utilizados para cacular o 
gradiente em uma única iteração, ou seja o conjuntos dos dados. Grandes conjuntos de dados
(milhões de  registros) podem conter um número enorme de recursos, a consequência disso
é que uma única iteração para calcular o gradiente descendente pode demorar muito.

Grandes bases de dados provavelmente contém dados redundantes, contudo essas bases de dados
não possuem muitos valores preditivos quando comparadado uma base de dados media.

Se pudessemos calcular o gradiente medio utilizando menos poder computacional? Escolhendo
exemplos aleatórios da nossa base de dados, podemos estimar (com ruido) uma grande média
utilizando uma quantidade de dados muito reduzida. Esta é a ideia do Gradiente Descendente
Estocastico (Stocastic Gradiente Descent). Para cada iteração é utilizado um único 
exemplo, dado um número suficiente de iterações o SGD funciona, porém possuí muito ruido.
O termo estocástico indica que os exemplos são selecionados aleatóriamente.

Gradiente Descendente Estocástico - Mini lote é um método intermediário entre o SGD e 
a iteração completa do Gradiente Descendente, um mini lote tipico contém de 10 a 1000 exemplos
escolhidos aleatóreamente. SGD - Mini lote reduz a quantidade de ruido do SGD e é mais
eficiente que a iteração completa.

////PLAY GROUND EXERCISE /// O playground é um programa desenvolvido especialmente para
ensinar os principios de Machine Learning. Para cada exercicio é gerado um conjunto de dados.
A meta do exercicio é ajustar vários hiperparametros para criar um modelo que classifica
(separa ou distingue) o valor dos rótulos. Os conjuntos de dados possuem ruido, e será
impossível classificar todos os exemplos.

Todos os exercícios apresentam uma visualização do atual estado do modelo construído:
	-Cada eixo da visualização apresentado representa um fator específico.
	-Cada ponto no gráfico representa um dado.
	-As cores dos pontos representam classes, por exemplo: Laranja homens, roxo mulheres.
	-A cor de fundo respresenta o local onde os exemplos devem ser plotados, de acordo
	com o modelo de predição. Um fundo laranja ao redor de um ponto laranja, indica que 
	o modelo fez a previsão correta. Um fundo roxo ao redor de um ponto laranja indica que
	a previsão do modelo está errada.
	-Ambas as cores de classificação possuem um gradiente que vai do tom mais escuro da
	cor em questão, até o branco. Este gradiente indica o grau de confiança da aferição
	do modelo. Cores mais escuras representam alto grau de confiança na previsão.
	-A visualização deve ser utilizada para avaliação do progresso de previsão e ajuste 
	do modelo.

Conhecendo o PLAYGROUND -> Primeiro execício, experimento com taxa de aprendizado.
	
TensorFlow é um framework computacional para construção de modelos de Machine Learning. Modelos
podem ser criados utilizando APIs de baixo nível(sequência de operações matemáticas), e alto
nível (funções e operações de alto nível como  regressão linear, e redes neurais).

A hierarquia das ferramentas do TensorFlor:
	Estimadores TF --------------------> API de alto nível orientada a objetos.
	ty.layers, tf.losses, tf.metrics --> Bibliotecas reutilizaveis, e modelos de componentes comuns.
	------------------------- APIS de baixo nível -----------------------------
	Python TF -------------------------> Camada para agregar Kernels C++.
	CPU-GPU-TPU -----------------------> Kernel funciona em uma ou mais plataformas.

O TensorFlow consiste de dois componentes:
	- Graph protocol buffer
	- Executaável (distribuido de grafos)
	
Ambos são análogos ao código Python e ao seu Interpretador. 

Todos os problemas que podem ser resolvidos utilizando a API de alto nível, também podem
ser resolvidos utilizando as API's de baixo nível. O tf.estimator é compatível com 
scikit-Learn (Bilbioteca muito Popular em Python).
Abaixo exemplo de código DE REGRESSÃOO LINEAR utilizando tf.estimator.

import tensorflow as tf

# O CLASSIFICADOR LINEAR É CONSTRUÍDO, UTILIZANDO AS VARIÁVEIS PREDITORAS (FEATURE_COLUMNS)
classifier = tf.estimator.LinearClassifier(feature_columns)

# O MODELO É TREINADO COM A BASE DE DADOS DE TREINO
classifier.train(input_fn=train_input_fn, steps=2000)

# O MODELO É UTILIZADO PARA PREVER VALORES
predictions = classifier.predict(input_fn=predict_input_fn)

PRIMEIROS PASSOS COM TENSOR FLOW: EXERCICIOS DE PROGRAMAÇÃO
Os exercícios são executados utilizando a API de alto nível tf.estimator.
Não é necessária instalação de software(recurso opcional).

EXERCICIO 1:
Introdução rápida ao Pandas: Uma biblioteca para analise de dados e modelagem. 
Muito utilizada em TensorFlor. Pandas é uma API orientado a colunas.

Conceitos básicos: As estruturas primarias são: 
DataFrame --> Pode ser imaginada como uma tabela de dados relacional, com linhas e colunas.
Series --> Unica coluna. Um DataFrame possuí uma ou mais Series.

//IMPORTAÇÃO DA BIBLIOTECA DO PANDAS
import pandas as pd

DataFrame é uma abstração para a manipulação de dados. A seguir um exemplo de como construir
um objeto Serie: pd.Series(['São Francisco', 'São José', 'São Paulo'])

Objetos DataFrame podem ser criados com um conjunto de series, com sintaxe igual a JSON:
	city_names = pd.Series(['San Francisco', 'San Jose', 'Sacramento'])
	population = pd.Series([852469, 1015785, 485199])

pd.DataFrame({ 'City name': city_names, 'Population': population }) <--- Criação do DataFrame
utilizando duas series.

Contudo, a maioria das vezes o DataFrame é carregado com dados de arquivos externos:
california_housing_dataframe = pd.read_csv("https://download.mlcc.google.com/mledu-datasets/california_housing_train.csv", sep=",")
california_housing_dataframe.describe() < -- Comando apresenta dados estatísticos sobre o 
DataFrame
california_housing_dataframe.head() < -- Comando que mostra as primeiras linhas do DataFrame.
california_housing_dataframe.hist('housing_median_age') <-- Apresenta distribuição dos valores
de uma coluna.

Acessando dados:
Os dados do dataframe são acessados usando as funções dict/list do Python.
//Crio um data frame com duas series, city_name e population
cities = pd.DataFrame({ 'City name': city_names, 'Population': population }) 
//APRESENTO TODOS OS VALORES DA SERIE
print(type(cities['City name']))
//TODOS OS VALORES DA LISTA SÃO ACESSADOS
cities['City name']

//ÚM ÚNICO REGISTRO DA SERIE É AREPSENTADO
print(type(cities['City name'][1]))
//UM ÚNICO REGISTRO DA SERIE É MOSTRADO
cities['City name'][1]

//DOIS REGISTROS DA SERIE SÃO MOSTRADOS
print(type(cities[0:2]))
//DOIS REGISTROS DA SERIE SÃO SELECIONADOS
cities[0:2]

Manipulação de dados
Operações aritiméticas do Python podem ser aplicadas as séries:
//SERIE population / 1000.

NumPy é um ferramenta para computação cientifica. As Series do panda podem ser utilizadas como parametros
para a maioria das funções do NumPy.

//IMPORTAÇÃO DA BIBLIOTECA DO NUMPY
import numpy as np

Para operações TRANFORMAÇÕES MAIS COMPLEXAS com series usar Series.apply. Similar a função map do Python:
//ESTE MÉTODO RETORNA UMA NOVA SERIE COM VALORES DE POPULAÇÃO MAIORES QUE 1 MILHÃO.
population.apply(lambda val: val > 1000000)

Modificando os DataFrames
//SÃO ADICIONADAS DUAS SERIES NOVAS PARA O DATAFRAME cities
cities['Area square miles'] = pd.Series([46.87, 176.53, 97.92])
cities['Population density'] = cities['Population'] / cities['Area square miles']
cities

Exercício 1:
Modifique a tabela Cidades adicionando uma nova coluna do tipo boolean. Esta coluna tem como valor VERDADEIRO
somente se: O nome da cidade vem depois de SAN (santo) e a cidade possuem mais de 50 milhas quadradas.
*AS CRIAÇÃO DE CONDIÇÕES UTILIZANDO VARIAS SERIES É FEITA COM & AO INVÉS DE AND.

//Função startwith verifica se a string possuí um substring de acordo com a passada no parâmetro.
Solução: cities['Is wide and has saint name'] = (cities['Area square miles'] > 50) 
& cities['City name'].apply(lambda name: name.startswith('San')) cities

Indices
Series e objetos DataFrame possuem a propriedade index, utilizado para identificar unicamente
cada Serie ou cada linha do DataFrame.
//INDICE DE UMA SERIE
city_names.index
//INDICE DE DE UM DATAFRAME
cities.index

Para reordenar as linhas manualmente utilize a função DataFrame.reindex([2,0,1]).
Essa função é útil para gerar ordenar de maneira aleatória os indices.
A função abaixo, utiliza a função random.permutaion da bilbioteca do num pi, recebendo como 
parametro os indices do DataFrama para gerar numeros aletórios para reordenar os indices.

cities.reindex(nm.random.permutaion(cities.index))

EXERCÍCIO 2

